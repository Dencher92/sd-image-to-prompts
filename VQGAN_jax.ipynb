{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b1df63-8431-4f7d-bdb9-29019da1f972",
   "metadata": {},
   "source": [
    "This is a JAX implementation of the VQGAN based on this: \n",
    "\n",
    "https://github.com/patil-suraj/vqgan-jax\n",
    "\n",
    "https://huggingface.co/flax-community/vqgan_f16_16384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b197be-a1cb-4cf4-95d0-5be4e9309953",
   "metadata": {},
   "source": [
    "However, I failed to run it with batch any larger than 18 images, although tried every possible combination of parameters. It just constantly fails with OOM. On the other hand I managed to run Pytorch implementation with batch size of 32, so I did not use Jax whatsoever.. Therefore I'll leave this notebook here just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e6d19e-52bb-4e2d-b5d3-d5583095265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "# os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "# os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.08'\n",
    "# os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] ='platform'\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "# os.environ['XLA_FLAGS'] = '--xla_gpu_strict_conv_algorithm_picker=false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6b18f-27e1-4708-b386-911b74a2be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vqgan_jax.modeling_flax_vqgan import VQModel\n",
    "\n",
    "VQGAN_COMMIT_ID = \"e93a26e7707683d349bf5d5c41c5b0ef69b677a9\"\n",
    "VQGAN_REPO = \"dalle-mini/vqgan_imagenet_f16_16384\"\n",
    "model, vqgan_params = VQModel.from_pretrained(\n",
    "    VQGAN_REPO, \n",
    "    revision=VQGAN_COMMIT_ID,\n",
    "    # _do_init=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc094e1-8403-45ce-bf91-87c70988a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f5210-abde-4b2e-9107-9adc6589da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url):\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    return Image.open(io.BytesIO(resp.content))\n",
    "\n",
    "def preprocess_vqgan(x):\n",
    "    x = 2.*x - 1.\n",
    "    return x\n",
    "\n",
    "def custom_to_pil(x):\n",
    "    x = np.clip(x, -1., 1.)\n",
    "    x = (x + 1.)/2.\n",
    "    x = (255*x).astype(np.uint8)\n",
    "    x = Image.fromarray(x)\n",
    "    if not x.mode == \"RGB\":\n",
    "        x = x.convert(\"RGB\")\n",
    "    return x\n",
    "\n",
    "def preprocess(img):\n",
    "    img = TF.resize(img, (512, 512), interpolation=Image.LANCZOS)\n",
    "    img = torch.unsqueeze(T.ToTensor()(img), 0)\n",
    "    return img.permute(0, 2, 3, 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95770b86-9cad-40c3-a816-15c7997a5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = '/mnt/home/data/diffusiondb_img/part-013448/cfb9cd9a-84f4-402a-9547-060654a1e9a3.webp'\n",
    "image = Image.open(test_img_path)\n",
    "image = preprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3fc038-9ddf-4cf5-a694-e0cca827997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = np.random.rand(30, 512, 512, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71fa4d-6ae1-4e74-9df9-52ba04a2f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_states, indices = model.encode(image_batch)\n",
    "rec = model.decode(quant_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cec4d3-6c3a-439e-bd0c-a442946211d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_to_pil(preprocess_vqgan(image[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9bde50-ee59-4e59-ae27-1844f0fea2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_to_pil(preprocess_vqgan(np.asarray(rec[0])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JAX VQGAN",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
